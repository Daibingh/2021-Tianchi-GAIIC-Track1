{
    "info": "None",
    "start_epoch": 1,
    "epochs": 300,
    "batch_size": 20,
    "optimizer": "adamw",
    "lr": 5e-05,
    "momentum": 0.9,
    "weight_decay": 0,
    "workers": 4,
    "dataset_splits": [
        8,
        0
    ],
    "shuffle_dataset": true,
    "random_seed": 937,
    "device": "cuda",
    "enable_logging": true,
    "enable_saving": true,
    "logging_path": "/content/drive/Shareddrives/daibingh/Ali_round1/bert_logging",
    "saving_path": "/content/drive/Shareddrives/daibingh/Ali_round1/bert_saving",
    "save_num_best": 1,
    "save_mode": "cycle",
    "save_model_name": "model",
    "save_every_epochs": 5,
    "save_last": true,
    "not_save_keys_file": null,
    "primary_score": "val_loss",
    "higher_better": false,
    "early_stop": true,
    "early_stop_num": 10,
    "folder_id": "bert_pretrain",
    "resume_path": null,
    "debug": false,
    "config_file": "config/task1/bert_pretrain_colab.json",
    "vocab_file": "data/vocab.pkl",
    "data_file": [
        "data/rd1_train.csv",
        "data/rd2_train.csv"
    ],
    "test_file": [
        "data/rd1_testA.csv",
        "data/rd1_testB.csv"
    ],
    "desc_max_len": null,
    "seq_pad_meth": "post",
    "mask_prob": 0.15,
    "mask_ngram": 2,
    "pretrain_model_file": null,
    "verbose": 1,
    "attention_probs_dropout_prob": 0.1,
    "gradient_checkpointing": false,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.1,
    "hidden_size": 768,
    "initializer_range": 0.02,
    "intermediate_size": 3072,
    "layer_norm_eps": 1e-12,
    "max_position_embeddings": 512,
    "model_type": "bert",
    "num_attention_heads": 12,
    "num_hidden_layers": 12,
    "pad_token_id": 0,
    "position_embedding_type": "absolute",
    "transformers_version": "4.6.0.dev0",
    "type_vocab_size": 1,
    "use_cache": false,
    "vocab_size": 863
}